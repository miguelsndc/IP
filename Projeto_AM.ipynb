{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelsndc/IP/blob/main/Projeto_AM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGxma_t9W6Tg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1. CARREGAR E PREPARAR OS DADOS\n",
        "# ============================================================\n",
        "\n",
        "# Carregue o arquivo yeast.data\n",
        "# Se estiver no Colab, faça upload do arquivo ou use:\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Ler o dataset (sem cabeçalho, separado por espaços)\n",
        "column_names = ['sequence_name', 'mcg', 'gvh', 'alm', 'mit', 'erl', 'pox', 'vac', 'nuc', 'class']\n",
        "df = pd.read_csv('yeast.data', sep='\\\\s+', names=column_names, header=None)\n",
        "\n",
        "print(\"Dataset Yeast carregado!\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\nPrimeiras linhas:\")\n",
        "print(df.head())\n",
        "print(f\"\\nDistribuição das classes:\")\n",
        "print(df['class'].value_counts())\n",
        "\n",
        "# Remover a coluna de nome da sequência (não é feature)\n",
        "X = df.drop(['sequence_name', 'class'], axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Codificar as classes\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "print(f\"\\nNúmero de features: {X.shape[1]}\")\n",
        "print(f\"Número de classes: {len(np.unique(y_encoded))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgLAR_ekYhdX",
        "outputId": "a6cc1121-aea8-4603-e37f-5cfc0b33894a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Yeast carregado!\n",
            "Shape: (1484, 10)\n",
            "\n",
            "Primeiras linhas:\n",
            "  sequence_name   mcg   gvh   alm   mit  erl  pox   vac   nuc class\n",
            "0    ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22   MIT\n",
            "1    ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22   MIT\n",
            "2    ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22   MIT\n",
            "3    AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22   NUC\n",
            "4    AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22   MIT\n",
            "\n",
            "Distribuição das classes:\n",
            "class\n",
            "CYT    463\n",
            "NUC    429\n",
            "MIT    244\n",
            "ME3    163\n",
            "ME2     51\n",
            "ME1     44\n",
            "EXC     35\n",
            "VAC     30\n",
            "POX     20\n",
            "ERL      5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Número de features: 8\n",
            "Número de classes: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 2. DIVISÃO ESTRATIFICADA DOS DADOS (70% treino, 30% teste)\n",
        "# ============================================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Normalizar os dados\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\nConjunto de treino: {X_train.shape[0]} amostras\")\n",
        "print(f\"Conjunto de teste: {X_test.shape[0]} amostras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnqmE_COYhyT",
        "outputId": "743114ce-a846-4505-a80e-a18a899dc595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conjunto de treino: 1038 amostras\n",
            "Conjunto de teste: 446 amostras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3. DEFINIR OS CLASSIFICADORES E HIPERPARÂMETROS\n",
        "# ============================================================\n",
        "\n",
        "# Configurar validação cruzada estratificada\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Dicionário com os classificadores e seus hiperparâmetros\n",
        "classifiers = {\n",
        "    'Decision Tree': {\n",
        "        'model': DecisionTreeClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'max_depth': [5, 10, 15, 20, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'criterion': ['gini', 'entropy']\n",
        "        }\n",
        "    },\n",
        "    'Naive Bayes': {\n",
        "        'model': GaussianNB(),\n",
        "        'params': {\n",
        "            'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
        "        }\n",
        "    },\n",
        "    'Logistic Regression': {\n",
        "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'params': {\n",
        "            'C': [0.01, 0.1, 1, 10, 100],\n",
        "            'penalty': ['l2'],\n",
        "            'solver': ['lbfgs', 'saga']\n",
        "        }\n",
        "    },\n",
        "    'K-Neighbors': {\n",
        "        'model': KNeighborsClassifier(),\n",
        "        'params': {\n",
        "            'n_neighbors': [3, 5, 7, 9, 11, 15, 20],\n",
        "            'weights': ['uniform', 'distance'],\n",
        "            'metric': ['euclidean']\n",
        "        }\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model': RandomForestClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [50, 100, 200],\n",
        "            'max_depth': [10, 20, 30, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "vSd7HzDqYh6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 4. TREINAR E OTIMIZAR CADA CLASSIFICADOR\n",
        "# ============================================================\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TREINAMENTO E OTIMIZAÇÃO DOS CLASSIFICADORES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, clf_info in classifiers.items():\n",
        "    print(f\"\\n{name}...\")\n",
        "\n",
        "    # Grid Search com validação cruzada\n",
        "    grid_search = GridSearchCV(\n",
        "        clf_info['model'],\n",
        "        clf_info['params'],\n",
        "        cv=cv,\n",
        "        scoring='f1_weighted',\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Melhor modelo\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predições\n",
        "    y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "    # Métricas\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'model': best_model,\n",
        "        'best_params': grid_search.best_params_,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'accuracy': accuracy,\n",
        "        'predictions': y_pred\n",
        "    }\n",
        "\n",
        "    print(f\"  Melhores hiperparâmetros: {grid_search.best_params_}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall: {recall:.4f}\")\n",
        "    print(f\"  F1-Score: {f1:.4f}\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzL5PfMVYh9y",
        "outputId": "f8dad9a7-b3a2-4a8f-b425-abc360509a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TREINAMENTO E OTIMIZAÇÃO DOS CLASSIFICADORES\n",
            "============================================================\n",
            "\n",
            "Decision Tree...\n",
            "  Melhores hiperparâmetros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
            "  Precision: 0.5133\n",
            "  Recall: 0.5314\n",
            "  F1-Score: 0.5191\n",
            "  Accuracy: 0.5314\n",
            "\n",
            "Naive Bayes...\n",
            "  Melhores hiperparâmetros: {'var_smoothing': 1e-06}\n",
            "  Precision: 0.4525\n",
            "  Recall: 0.1928\n",
            "  F1-Score: 0.2220\n",
            "  Accuracy: 0.1928\n",
            "\n",
            "Logistic Regression...\n",
            "  Melhores hiperparâmetros: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "  Precision: 0.5933\n",
            "  Recall: 0.5964\n",
            "  F1-Score: 0.5836\n",
            "  Accuracy: 0.5964\n",
            "\n",
            "K-Neighbors...\n",
            "  Melhores hiperparâmetros: {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n",
            "  Precision: 0.6055\n",
            "  Recall: 0.6121\n",
            "  F1-Score: 0.6002\n",
            "  Accuracy: 0.6121\n",
            "\n",
            "Random Forest...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 5. COMPARAÇÃO DOS RESULTADOS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARAÇÃO DOS CLASSIFICADORES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Classifier': list(results.keys()),\n",
        "    'Precision': [results[k]['precision'] for k in results.keys()],\n",
        "    'Recall': [results[k]['recall'] for k in results.keys()],\n",
        "    'F1-Score': [results[k]['f1'] for k in results.keys()],\n",
        "    'Accuracy': [results[k]['accuracy'] for k in results.keys()]\n",
        "})\n",
        "\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Visualização\n",
        "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy']\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    axes[idx].bar(comparison_df['Classifier'], comparison_df[metric], color='skyblue')\n",
        "    axes[idx].set_title(f'{metric}', fontsize=14, fontweight='bold')\n",
        "    axes[idx].set_ylabel(metric)\n",
        "    axes[idx].set_ylim([0, 1])\n",
        "    axes[idx].tick_params(axis='x', rotation=45)\n",
        "    axes[idx].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OpLj84ueYiA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 6. CURVAS DE APRENDIZAGEM\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GERANDO CURVAS DE APRENDIZAGEM\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Tamanhos de treino de 5% a 95% com passo de 5%\n",
        "train_sizes = np.arange(0.05, 1.0, 0.05)\n",
        "\n",
        "learning_curves = {name: {'train_precision': [], 'test_precision': [],\n",
        "                          'train_recall': [], 'test_recall': [],\n",
        "                          'train_f1': [], 'test_f1': [],\n",
        "                          'train_sizes': []}\n",
        "                   for name in results.keys()}\n",
        "\n",
        "for train_size in train_sizes:\n",
        "    test_size = 1 - train_size\n",
        "\n",
        "    # Divisão estratificada\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X, y_encoded, test_size=test_size, random_state=42, stratify=y_encoded\n",
        "    )\n",
        "\n",
        "    # Normalizar\n",
        "    scaler_temp = StandardScaler()\n",
        "    X_tr_scaled = scaler_temp.fit_transform(X_tr)\n",
        "    X_te_scaled = scaler_temp.transform(X_te)\n",
        "\n",
        "    for name in results.keys():\n",
        "        # Treinar o modelo com os melhores hiperparâmetros\n",
        "        model = results[name]['model']\n",
        "        model.fit(X_tr_scaled, y_tr)\n",
        "\n",
        "        # Predições no treino e teste\n",
        "        y_tr_pred = model.predict(X_tr_scaled)\n",
        "        y_te_pred = model.predict(X_te_scaled)\n",
        "\n",
        "        # Métricas\n",
        "        learning_curves[name]['train_precision'].append(\n",
        "            precision_score(y_tr, y_tr_pred, average='weighted', zero_division=0))\n",
        "        learning_curves[name]['test_precision'].append(\n",
        "            precision_score(y_te, y_te_pred, average='weighted', zero_division=0))\n",
        "        learning_curves[name]['train_recall'].append(\n",
        "            recall_score(y_tr, y_tr_pred, average='weighted', zero_division=0))\n",
        "        learning_curves[name]['test_recall'].append(\n",
        "            recall_score(y_te, y_te_pred, average='weighted', zero_division=0))\n",
        "        learning_curves[name]['train_f1'].append(\n",
        "            f1_score(y_tr, y_tr_pred, average='weighted', zero_division=0))\n",
        "        learning_curves[name]['test_f1'].append(\n",
        "            f1_score(y_te, y_te_pred, average='weighted', zero_division=0))\n",
        "        learning_curves[name]['train_sizes'].append(train_size * 100)\n",
        "\n",
        "print(\"Curvas de aprendizagem calculadas!\")"
      ],
      "metadata": {
        "id": "-jet9yePYiHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 7. PLOTAR CURVAS DE APRENDIZAGEM\n",
        "# ============================================================\n",
        "\n",
        "metrics_to_plot = ['precision', 'recall', 'f1']\n",
        "\n",
        "for metric in metrics_to_plot:\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    fig.suptitle(f'Curvas de Aprendizagem - {metric.upper()}', fontsize=16, fontweight='bold')\n",
        "\n",
        "    for idx, name in enumerate(results.keys()):\n",
        "        row = idx // 3\n",
        "        col = idx % 3\n",
        "\n",
        "        ax = axes[row, col]\n",
        "\n",
        "        train_key = f'train_{metric}'\n",
        "        test_key = f'test_{metric}'\n",
        "\n",
        "        ax.plot(learning_curves[name]['train_sizes'],\n",
        "                learning_curves[name][train_key],\n",
        "                'o-', label='Treino', linewidth=2, markersize=4)\n",
        "        ax.plot(learning_curves[name]['train_sizes'],\n",
        "                learning_curves[name][test_key],\n",
        "                's-', label='Teste', linewidth=2, markersize=4)\n",
        "\n",
        "        ax.set_xlabel('% Treino', fontsize=10)\n",
        "        ax.set_ylabel(metric.capitalize(), fontsize=10)\n",
        "        ax.set_title(name, fontsize=12, fontweight='bold')\n",
        "        ax.legend(loc='best')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_ylim([0, 1.05])\n",
        "\n",
        "    # Remover subplot extra se houver\n",
        "    if len(results.keys()) < 6:\n",
        "        fig.delaxes(axes[1, 2])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "a-5stYRsY_43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 8. ANÁLISE E COMENTÁRIOS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANÁLISE DOS RESULTADOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n1. DESEMPENHO DOS CLASSIFICADORES:\")\n",
        "best_f1 = max(results.items(), key=lambda x: x[1]['f1'])\n",
        "print(f\"   - Melhor F1-Score: {best_f1[0]} ({best_f1[1]['f1']:.4f})\")\n",
        "\n",
        "best_precision = max(results.items(), key=lambda x: x[1]['precision'])\n",
        "print(f\"   - Melhor Precision: {best_precision[0]} ({best_precision[1]['precision']:.4f})\")\n",
        "\n",
        "best_recall = max(results.items(), key=lambda x: x[1]['recall'])\n",
        "print(f\"   - Melhor Recall: {best_recall[0]} ({best_recall[1]['recall']:.4f})\")\n",
        "\n",
        "print(\"\\n2. OBSERVAÇÕES DAS CURVAS DE APRENDIZAGEM:\")\n",
        "print(\"   - Overfitting: ocorre quando a curva de treino está muito acima da de teste\")\n",
        "print(\"   - Underfitting: ocorre quando ambas as curvas estão baixas\")\n",
        "print(\"   - Bom ajuste: curvas próximas e em valores altos\")\n",
        "print(\"   - Com mais dados de treino, o desempenho no teste tende a melhorar\")\n",
        "\n",
        "print(\"\\n3. MELHORES HIPERPARÂMETROS POR CLASSIFICADOR:\")\n",
        "for name, result in results.items():\n",
        "    print(f\"   {name}:\")\n",
        "    for param, value in result['best_params'].items():\n",
        "        print(f\"     - {param}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANÁLISE COMPLETA!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "AK8aQ5WxY_wG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}